{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done..\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "\n",
    "min_count = 2\n",
    "size = 50\n",
    "window = 4\n",
    "word2vec_model = Word2Vec(min_count=min_count, size=size, window=window)\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('googlenews.vectors.bin', binary=True)\n",
    "print('Done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(f):\n",
    "    df_complete = pd.read_csv(f)\n",
    "    return df_complete\n",
    "\n",
    "reviewsDFComplete = read_text_file(\"finland_hotel_reviews.csv\")\n",
    "#print(reviewsDFComplete['review'])\n",
    "\n",
    "reviewsDFComplete['review'] = reviewsDFComplete['review'].apply(lambda row: str(row).lower())\n",
    "reviewsDFComplete['tokens']=reviewsDFComplete.apply(lambda row: word_tokenize(str(row['review'])), axis=1)  # Search for all non-letters\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "# Keeping stopwords increased accuracy\n",
    "# Remove stopwords , numeric and alphanumeric characters\n",
    "#reviewsDFComplete['tokens'] = reviewsDFComplete['review'].apply(lambda row: [row for row in row.split() if row not in stop and row.isalpha()])\n",
    "reviewsDFComplete['tokens'] = reviewsDFComplete['tokens'].apply(lambda row: \",\".join(row))\n",
    "reviewsDFComplete['review_length'] = reviewsDFComplete.apply(lambda row: len(row['tokens']), axis=1)\n",
    "reviewvector = np.zeros(shape=(reviewsDFComplete.shape[0], 300))\n",
    "for index, row in reviewsDFComplete.iterrows():\n",
    "    review_word = list(filter(lambda word: word in word2vec_model.vocab, row['tokens'].split(',')))\n",
    "    #print(review_word)\n",
    "    review_vector_word=[]\n",
    "    if len(review_word) > 0:\n",
    "        for word in review_word:\n",
    "            review_vector_word.append(word2vec_model[word])  # Vector representation of each word in review\n",
    "    \n",
    "    #print(review_vector_word)\n",
    "    # vector of 300 dims representation of each review\n",
    "    review_vector = np.array(np.sum(review_vector_word, axis=0) / np.sqrt((np.sum(review_vector_word, axis=0) ** 2).sum()))\n",
    "    #print(len(review_vector), len(review_vector_word))\n",
    "    review_vector = review_vector.reshape(1, review_vector.shape[0])\n",
    "    reviewvector[index]=review_vector\n",
    "    \n",
    "for i in range(0, 300):\n",
    "    reviewsDFComplete[\"review_vector_\" + str(i)] = reviewvector[:, i]\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   current_price_per_night  average_rating  total_reviews_received  rating  \\\n",
      "0                      123             4.5                  2018.0     5.0   \n",
      "1                      123             4.5                  2018.0     5.0   \n",
      "2                      123             4.5                  2018.0     5.0   \n",
      "3                      123             4.5                  2018.0     3.0   \n",
      "4                      123             4.5                  2018.0     5.0   \n",
      "\n",
      "   review_length  review_vector_0  review_vector_1  review_vector_2  \\\n",
      "0            268        -0.023419         0.061145        -0.000526   \n",
      "1            225        -0.054742         0.049039         0.008964   \n",
      "2            265         0.002349         0.040305        -0.013221   \n",
      "3            247         0.053206         0.040323         0.037969   \n",
      "4            249         0.016664         0.030725         0.024672   \n",
      "\n",
      "   review_vector_3  review_vector_4        ...          review_vector_290  \\\n",
      "0         0.105235        -0.085532        ...                  -0.104901   \n",
      "1         0.085757        -0.088087        ...                  -0.047322   \n",
      "2         0.124922        -0.043397        ...                  -0.068692   \n",
      "3         0.061374        -0.049498        ...                  -0.138369   \n",
      "4         0.079524        -0.040505        ...                  -0.081907   \n",
      "\n",
      "   review_vector_291  review_vector_292  review_vector_293  review_vector_294  \\\n",
      "0           0.020724          -0.066386           0.082476           0.003901   \n",
      "1           0.024663          -0.059538           0.101197          -0.006906   \n",
      "2           0.036263          -0.093491           0.045762           0.004559   \n",
      "3           0.035174          -0.097708           0.049188          -0.033739   \n",
      "4           0.039617          -0.112677           0.052019          -0.002302   \n",
      "\n",
      "   review_vector_295  review_vector_296  review_vector_297  review_vector_298  \\\n",
      "0           0.015262           0.004186          -0.057077           0.109004   \n",
      "1          -0.002657           0.038493          -0.072262           0.051500   \n",
      "2          -0.000723           0.030111          -0.043509           0.033864   \n",
      "3          -0.026861           0.011035          -0.032421           0.060806   \n",
      "4          -0.009176          -0.035341          -0.044643           0.066026   \n",
      "\n",
      "   review_vector_299  \n",
      "0          -0.020768  \n",
      "1           0.016198  \n",
      "2          -0.034661  \n",
      "3          -0.020989  \n",
      "4          -0.005431  \n",
      "\n",
      "[5 rows x 305 columns]\n",
      "0    5.0\n",
      "1    5.0\n",
      "2    5.0\n",
      "3    3.0\n",
      "4    5.0\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reviewsDF = reviewsDFComplete\n",
    "reviewsDF = reviewsDF.drop('review_title',1)\n",
    "reviewsDF = reviewsDF.drop('address',1)\n",
    "reviewsDF = reviewsDF.drop('lat',1)\n",
    "reviewsDF = reviewsDF.drop('lng',1)\n",
    "reviewsDF = reviewsDF.drop('rating_date',1)\n",
    "reviewsDF = reviewsDF.drop('review',1)\n",
    "reviewsDF = reviewsDF.drop('tokens',1)\n",
    "reviewsDF = reviewsDF.drop('name',1)\n",
    "reviewsDF = reviewsDF.drop('reviewer_nationality',1)\n",
    "reviewsDF = reviewsDF.drop('tags',1)\n",
    "\n",
    "#ratingsDF = (reviewsDF['rating'] >= 4).astype('int')\n",
    "ratingsDF = reviewsDF['rating']\n",
    "print(reviewsDF.head())\n",
    "print(ratingsDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression    \n",
    "    \n",
    "training_data, test_data, train_target, test_target = train_test_split(reviewsDF, ratingsDF, train_size=0.8, test_size=0.2)\n",
    "model = LogisticRegression()\n",
    "#print(training_data.head(), train_target.head())\n",
    "ovr = OneVsRestClassifier(model).fit(training_data, train_target)\n",
    "dummy = DummyClassifier('most_frequent')\n",
    "dummy.fit(training_data, train_target)\n",
    "\n",
    "#predicting & comparing\n",
    "predictedOvr = ovr.predict(test_data)\n",
    "predictedDummy = dummy.predict(test_data)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data\n",
      "[ 5.  4.  5. ...,  5.  4.  5.]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Real data')\n",
    "print(np.asarray(test_target))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority classifier result\n",
      "[ 5.  5.  5. ...,  5.  5.  5.]\n",
      "Majority classifier accuracy: 0.404494382022\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Majority classifier result')\n",
    "print(predictedDummy)\n",
    "print('Majority classifier accuracy:', accuracy_score(test_target,predictedDummy))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVR predictor result\n",
      "[ 5.  4.  5. ...,  5.  4.  5.]\n",
      "OVR accuracy: 0.83595505618\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('OVR predictor result')\n",
    "print(predictedOvr)\n",
    "print('OVR accuracy:', accuracy_score(test_target,predictedOvr))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845505617978\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(training_data, train_target)\n",
    "print(accuracy_score(test_target, lr.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826404494382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(training_data, train_target)\n",
    "\n",
    "print(accuracy_score(test_target, rf.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 6/12 [01:06<01:14, 12.41s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  75%|███████▌  | 9/12 [02:51<01:20, 26.98s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 1.0\n",
      "\n",
      "Best pipeline: GaussianNB(input_matrix)\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=3, population_size=3, verbosity=2, max_eval_time_mins=2)\n",
    "tpot.fit(training_data, train_target)\n",
    "print(tpot.score(test_data, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826404494382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(training_data, train_target)\n",
    "print(accuracy_score(test_target, rf.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-venv",
   "language": "python",
   "name": "my-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
